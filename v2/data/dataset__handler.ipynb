{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "import os.path\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/faridbala/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_data(name, seed=1234):\n",
    "    \"\"\"\n",
    "    Load one of MR, CR, SUBJ or MPQA\n",
    "    \"\"\"\n",
    "    z = {}\n",
    "    if name == 'rt-polarity':\n",
    "        pos, neg = load_rt()\n",
    "    elif name == 'Subjectivity_datasets':\n",
    "        pos, neg = load_subj()\n",
    "    elif name == 'review_polarity':\n",
    "        pos, neg = load_polarity()\n",
    "#     elif name == 'MPQA':\n",
    "#         pos, neg = load_mpqa(loc=loc)\n",
    "\n",
    "    labels = compute_labels(pos, neg)\n",
    "    text, labels = un_shuffle_data(pos+neg, labels, seed=seed)\n",
    "    z['text'] = text\n",
    "    z['labels'] = labels\n",
    "#     print(\"Type of text is {}\".format(text))\n",
    "#     features = encoder.encode(text)\n",
    "\n",
    "    return z#, features\n",
    "\n",
    "\n",
    "def load_rt(loc = './dataset/Sentiment_polarity_datasets/rt_polaritydata/rt-polaritydata/'):\n",
    "    \"\"\"\n",
    "    Load the rt-polarity dataset\n",
    "    \"\"\"\n",
    "    pos, neg = [], []\n",
    "    with open(os.path.join(loc, 'rt-polarity.pos'), 'rb') as f:\n",
    "        for line in f:\n",
    "            pos.append(line.decode('latin-1').strip())\n",
    "    with open(os.path.join(loc, 'rt-polarity.neg'), 'rb') as f:\n",
    "        for line in f:\n",
    "            neg.append(line.decode('latin-1').strip())\n",
    "    return pos, neg\n",
    "\n",
    "\n",
    "def load_subj(loc='./dataset/Subjectivity_datasets/rotten_imdb/'):\n",
    "    \"\"\"\n",
    "    Load the Subjectivity_datasets dataset\n",
    "    \"\"\"\n",
    "    pos, neg = [], []\n",
    "    with open(os.path.join(loc, 'plot.tok.gt9.5000'), 'rb') as f:\n",
    "        for line in f:\n",
    "            pos.append(line.decode('latin-1').strip())\n",
    "    with open(os.path.join(loc, 'quote.tok.gt9.5000'), 'rb') as f:\n",
    "        for line in f:\n",
    "            neg.append(line.decode('latin-1').strip())\n",
    "    return pos, neg\n",
    "\n",
    "\n",
    "def load_polarity(loc='./dataset/Sentiment_polarity_datasets/review_polarity/txt_sentoken/'):\n",
    "    \"\"\"\n",
    "    Load the review_polarity dataset\n",
    "    \"\"\"\n",
    "    pos, neg = [], []\n",
    "    temp_path = os.path.join(loc, 'pos')\n",
    "    for file in os.listdir(temp_path):\n",
    "        with open(os.path.join(temp_path, file), 'rb') as f:\n",
    "            for line in f:\n",
    "                text = line.decode(\"utf-8\").strip()\n",
    "                if len(text) > 0:\n",
    "                    pos.append(text)\n",
    "    temp_path = os.path.join(loc, 'neg')\n",
    "    for file in os.listdir(temp_path):\n",
    "        with open(os.path.join(temp_path, file), 'rb') as f:\n",
    "            for line in f:\n",
    "                text = line.decode(\"utf-8\").strip()\n",
    "                if len(text) > 0:\n",
    "                    neg.append(text)\n",
    "    return pos, neg\n",
    "\n",
    "\n",
    "# def load_mpqa(loc='./data/'):\n",
    "#     \"\"\"\n",
    "#     Load the MPQA dataset\n",
    "#     \"\"\"\n",
    "#     pos, neg = [], []\n",
    "#     with open(os.path.join(loc, 'mpqa.pos'), 'rb') as f:\n",
    "#         for line in f:\n",
    "#             text = line.strip()\n",
    "#             if len(text) > 0:\n",
    "#                 pos.append(text)\n",
    "#     with open(os.path.join(loc, 'mpqa.neg'), 'rb') as f:\n",
    "#         for line in f:\n",
    "#             text = line.strip()\n",
    "#             if len(text) > 0:\n",
    "#                 neg.append(text)\n",
    "#     return pos, neg\n",
    "\n",
    "\n",
    "def compute_labels(pos, neg):\n",
    "    \"\"\"\n",
    "    Construct list of labels\n",
    "    \"\"\"\n",
    "    labels = np.zeros(len(pos) + len(neg))\n",
    "    labels[:len(pos)] = 1.0\n",
    "    labels[len(pos):] = 0.0\n",
    "    return labels\n",
    "\n",
    "\n",
    "def un_shuffle_data(X, L, seed=1234):\n",
    "    \"\"\"\n",
    "    Shuffle the data\n",
    "    \"\"\"\n",
    "#     prng = RandomState(seed)\n",
    "    inds = np.arange(len(X))\n",
    "#     prng.shuffle(inds)\n",
    "    X = [X[i] for i in inds]\n",
    "    L = L[inds]\n",
    "    return (X, L) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_review_polarity = load_data('review_polarity')['text']\n",
    "label_review_polarity = load_data('review_polarity')['labels']\n",
    "\n",
    "text_rt_polarity = load_data('rt-polarity')['text']\n",
    "label_rt_polarity = load_data('rt-polarity')['labels']\n",
    "\n",
    "text_Subjectivity_datasets = load_data('Subjectivity_datasets')['text']\n",
    "label_Subjectivity_datasets = load_data('Subjectivity_datasets')['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the dream team is a thoroughly entertaining comedy featuring four loveable characters who just happen to be slightly insane .'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_review_polarity[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.4150e-05, 1.6970e-07, 1.0140e-08, 1.6782e-07, 6.2983e-10, 4.4157e-05,\n",
       "         1.4927e-19, 1.6223e-07, 4.1724e-08, 2.5193e-09]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('./gensim-develop/gensim/test/test_data/word2vec_pre_kv_c',\n",
    "                                                        binary=True)    \n",
    "# './word2vec_pre_kv_c'  from :   https://github.com/RaRe-Technologies/gensim/tree/develop/gensim/test/test_data\n",
    "weights = torch.FloatTensor(model.vectors) # formerly syn0, which is soon deprecated\n",
    "embedding = nn.Embedding.from_pretrained(weights)\n",
    "\n",
    "# Get embeddings for index 1\n",
    "input = torch.LongTensor([1])\n",
    "embedding(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_tok(txt):\n",
    "\n",
    "    tokens = word_tokenize(txt)\n",
    "    \n",
    "# @@@@@@@@ if wanna remove remaining tokens that are not alphabetic uncomment line belove\n",
    "    \n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_tokens = sent_to_tok(text_review_polarity[42124])\n",
    "len(dummy_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dictionary(name):\n",
    "    words = []\n",
    "    text = load_data(name)['text']\n",
    "    for txt in text:\n",
    "        tokens = sent_to_tok(txt)\n",
    "        for tok in tokens:\n",
    "            words.append(tok)\n",
    "    return words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_dictionary('rt_polarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_polarity_dic = build_dictionary('review_polarity')\n",
    "rt_polarity_dic = build_dictionary('rt-polarity')\n",
    "Subjectivity_datasets_dic = build_dictionary('Subjectivity_datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = review_polarity_dic + rt_polarity_dic + Subjectivity_datasets_dic\n",
    "\n",
    "dictionary = list(set(dict_))     #  44432 unique words out of 1675838 words in whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44432"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(txt):\n",
    "    dec = []\n",
    "    for w in txt:\n",
    "        code = dictionary.index(w)\n",
    "        dec.append(code)\n",
    "    return np.asarray(dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11461, 36070, 40415, 25768, 15897,  2254, 22615, 32514, 39627,\n",
       "       14144, 31202, 17625,   777, 44014, 27136, 14283, 35855, 32244,\n",
       "       16037,  3455, 22811, 32514, 36227, 17730, 24293, 32514, 15615,\n",
       "       34511, 22615,  3238, 14283, 32514,  1980, 40471, 24137, 20624,\n",
       "       28913, 40070, 27622,    59, 32553, 22495,  1794,  8326,  7946,\n",
       "        7467, 19267, 16083, 21511, 17823, 11475, 22615,  6946, 24505,\n",
       "       24763, 14109, 17827, 40892, 27136, 32514, 38606, 17270,  3455,\n",
       "       20445,  7834, 20655, 24763, 21175, 11480, 32479, 29246, 18191,\n",
       "       29657,  6298, 42247, 40892,  6188, 34143,  3455,  5835, 14283,\n",
       "       15859, 37359, 30113, 17823,  2769, 24763, 14109, 39156, 36070,\n",
       "       16539,  1980, 36234, 32244,  3023,  7794, 36234,  7946, 12447,\n",
       "       19303, 32699, 28937, 22615, 10837, 17823, 38624, 23089, 35101,\n",
       "       24763,  7131, 29657, 43271,  6188, 32514, 21161,  5835, 14506,\n",
       "       27136, 15859,  3023, 17823,  6203, 27622, 17730, 24234, 16040,\n",
       "       27622, 22615, 24137,    25,  3455, 37049, 17823, 42034, 31202,\n",
       "       40415, 24012, 27203,  7964, 32514,  3455,  7964, 29076, 27136,\n",
       "       20269, 32514, 27452, 31202, 39785,  4163, 19267, 30132])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_array = encoder(dummy_tokens)\n",
    "dummy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len_ = []\n",
    "# jj = 0\n",
    "# for i, j in enumerate(text_Subjectivity_datasets):\n",
    "#     if len(j)> jj:\n",
    "#         jj = len(j)\n",
    "#         print(j)\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'since that plot is incredibly lame and a track record of what goes on with it wouldn\\'t be able to carry a commercial let alone a feature film , and because it\\'s a party , there are some more main characters , such as : william ( charlie korsmo , finally surfacing after \" dick tracy \" ) , the nerd ( and his dominions ) who has come up with a ridiculous plan to publically sabotage mike , who\\'s humiliated him for years , but gets too caught up in drinking to do it ; kenny ( seth green ) , the wigger , who has decided that this party will be where he will finally get laid ( uh huh ) ; and denise , the only exceptional character , who unfortunately gets stuck in a bathroom ( don\\'t ask ) with kenny where the two characters let down their characters and are allowed to follow the laws of plot cliches from point a to point b with nary a bit of characterization involved after awhile .'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_review_polarity[42124]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "887"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_review_polarity[42124])     # max len in whole dataset without prepross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largest_sentence = len(sent_to_tok(text_review_polarity[42124]))   # max len in whole dataset without prepross\n",
    "largest_sentence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
